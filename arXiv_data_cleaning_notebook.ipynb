{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics as stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side note to self for _xsrf error: https://stackoverflow.com/questions/55014094/jupyter-notebook-not-saving-xsrf-argument-missing-from-post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Was downloaded on 1/1/2021 from: https://www.kaggle.com/Cornell-University/arxiv\n",
    "file_path = 'arxiv-metadata-oai-snapshot.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"0704.0001\",\"submitter\":\"Pavel Nadolsky\",\"authors\":\"C. Bal\\\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\",\"title\":\"Calculation of prompt diphoton production cross sections at Tevatron and\\n  LHC energies\",\"comments\":\"37 pages, 15 figures; published version\",\"journal-ref\":\"Phys.Rev.D76:013009,2007\",\"doi\":\"10.1103/PhysRevD.76.013009\",\"report-no\":\"ANL-HEP-PR-07-12\",\"categories\":\"hep-ph\",\"license\":null,\"abstract\":\"  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n\",\"versions\":[{\"version\":\"v1\",\"created\":\"Mon, 2 Apr 2007 19:18:42 GMT\"},{\"version\":\"v2\",\"created\":\"Tue, 24 Jul 2007 20:10:27 GMT\"}],\"update_date\":\"2008-11-26\",\"authors_parsed\":[[\"Bal\\u00e1zs\",\"C.\",\"\"],[\"Berger\",\"E. L.\",\"\"],[\"Nadolsky\",\"P. M.\",\"\"],[\"Yuan\",\"C. -P.\",\"\"]]}\n",
      "\n",
      "{\"id\":\"0704.0002\",\"submitter\":\"Louis Theran\",\"authors\":\"Ileana Streinu and Louis Theran\",\"title\":\"Sparsity-certifying Graph Decompositions\",\"comments\":\"To appear in Graphs and Combinatorics\",\"journal-ref\":null,\"doi\":null,\"report-no\":null,\"categories\":\"math.CO cs.CG\",\"license\":\"http://arxiv.org/licenses/nonexclusive-distrib/1.0/\",\"abstract\":\"  We describe a new algorithm, the $(k,\\\\ell)$-pebble game with colors, and use\\nit obtain a characterization of the family of $(k,\\\\ell)$-sparse graphs and\\nalgorithmic solutions to a family of problems concerning tree decompositions of\\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\\nreceived increased attention in recent years. In particular, our colored\\npebbles generalize and strengthen the previous results of Lee and Streinu and\\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\\nalso present a new decomposition that certifies sparsity based on the\\n$(k,\\\\ell)$-pebble game with colors. Our work also exposes connections between\\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\\nWestermann and Hendrickson.\\n\",\"versions\":[{\"version\":\"v1\",\"created\":\"Sat, 31 Mar 2007 02:26:18 GMT\"},{\"version\":\"v2\",\"created\":\"Sat, 13 Dec 2008 17:26:00 GMT\"}],\"update_date\":\"2008-12-13\",\"authors_parsed\":[[\"Streinu\",\"Ileana\",\"\"],[\"Theran\",\"Louis\",\"\"]]}\n",
      "\n",
      "{\"id\":\"0704.0003\",\"submitter\":\"Hongjun Pan\",\"authors\":\"Hongjun Pan\",\"title\":\"The evolution of the Earth-Moon system based on the dark matter field\\n  fluid model\",\"comments\":\"23 pages, 3 figures\",\"journal-ref\":null,\"doi\":null,\"report-no\":null,\"categories\":\"physics.gen-ph\",\"license\":null,\"abstract\":\"  The evolution of Earth-Moon system is described by the dark matter field\\nfluid model proposed in the Meeting of Division of Particle and Field 2004,\\nAmerican Physical Society. The current behavior of the Earth-Moon system agrees\\nwith this model very well and the general pattern of the evolution of the\\nMoon-Earth system described by this model agrees with geological and fossil\\nevidence. The closest distance of the Moon to Earth was about 259000 km at 4.5\\nbillion years ago, which is far beyond the Roche's limit. The result suggests\\nthat the tidal friction may not be the primary cause for the evolution of the\\nEarth-Moon system. The average dark matter field fluid constant derived from\\nEarth-Moon system data is 4.39 x 10^(-22) s^(-1)m^(-1). This model predicts\\nthat the Mars's rotation is also slowing with the angular acceleration rate\\nabout -4.38 x 10^(-22) rad s^(-2).\\n\",\"versions\":[{\"version\":\"v1\",\"created\":\"Sun, 1 Apr 2007 20:46:54 GMT\"},{\"version\":\"v2\",\"created\":\"Sat, 8 Dec 2007 23:47:24 GMT\"},{\"version\":\"v3\",\"created\":\"Sun, 13 Jan 2008 00:36:28 GMT\"}],\"update_date\":\"2008-01-13\",\"authors_parsed\":[[\"Pan\",\"Hongjun\",\"\"]]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/jupyter/help/issues/201\n",
    "with open('arxiv-metadata-oai-snapshot.json') as f:\n",
    "    for _ in range(3):\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes article metadata as a string and returns the arXiv shorthand for categories seperated by a space\n",
    "def clean_cats(data):\n",
    "    spl = data.split('\"categories\":')[1].split(',\"license\"')[0]\n",
    "    return spl[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes article metadata as a string and returns the title (without quotation marks)\n",
    "def clean_title(data):\n",
    "    spl = data.split('\"title\":')[1].split(',\"comments\":')[0]\n",
    "    return spl[1:-1].replace('\\\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes article metadata as a string and returns abstract (without quotation marks)\n",
    "def clean_ab(data):\n",
    "    spl = data.split('\"abstract\":')[1].split(',\"versions\":')[0]\n",
    "    return spl[3:-1].replace('\\\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes categories as a string (i.e. as the result of clean_cats) and returns the general category they fall under (by majority)\n",
    "# currently, a paper with equal tags in more than one subject is \"randomly\" chosen to be categorized by one of them\n",
    "# https://arxiv.org/category_taxonomy\n",
    "def gen_cat(cats):\n",
    "    math = q_bio = cs = q_fin = stat = eess = econ = physics = 0\n",
    "    gen_cat_list = ['math', 'q-bio', 'cs', 'q-fin', 'stat', 'eess', 'econ']\n",
    "    physics_list = ['astro-ph', 'cond-mat', 'gr-qc', 'hep-ex', 'hep-lat', 'hep-ph', 'hep-th', 'math-ph', 'nlin', 'nucl-ex',\n",
    "                   'nucl-th', 'physics', 'quant-ph']\n",
    "    cat_list = cats.split(' ')\n",
    "    for cat in cat_list:\n",
    "        if cat.split('.')[0] == 'math':\n",
    "            math+=1\n",
    "        elif cat.split('.')[0] == 'q-bio':\n",
    "            q_bio+=1\n",
    "        elif cat.split('.')[0] == 'cs':\n",
    "            cs+=1\n",
    "        elif cat.split('.')[0] == 'q-fin':\n",
    "            q_fin+=1\n",
    "        elif cat.split('.')[0] == 'stat':\n",
    "            stat+=1\n",
    "        elif cat.split('.')[0] == 'eess':\n",
    "            eess+=1\n",
    "        elif cat.split('.')[0] == 'econ':\n",
    "            econ+=1\n",
    "        elif cat.split('.')[0] in physics_list:\n",
    "            physics+=1\n",
    "    l = [math, q_bio, cs, q_fin, stat, eess, econ, physics]\n",
    "    gen_cat_list.append('physics')\n",
    "    return gen_cat_list[l.index(max(l))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hep-ph\n",
      "physics\n",
      "\n",
      "math.CO cs.CG\n",
      "math\n",
      "\n",
      "physics.gen-ph\n",
      "physics\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/jupyter/help/issues/201\n",
    "with open('arxiv-metadata-oai-snapshot.json') as f:\n",
    "    for _ in range(3):\n",
    "        l = f.readline()\n",
    "        print(clean_cats(l))\n",
    "        print(gen_cat(clean_cats(l)))\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = int(5e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat, title, ab = [], [], []\n",
    "\n",
    "# https://github.com/jupyter/help/issues/201\n",
    "with open(file_path) as f:\n",
    "    for _ in range(THRESHOLD):\n",
    "        t = f.readline()\n",
    "        title.append(clean_title(t))\n",
    "        ab.append(clean_ab(t))\n",
    "        cat.append(gen_cat(clean_cats(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['physics', 'math']\n",
      "['Calculation of prompt diphoton production cross sections at Tevatron and  LHC energies', 'Sparsity-certifying Graph Decompositions']\n",
      "['A fully differential calculation in perturbative quantum chromodynamics ispresented for the production of massive photon pairs at hadron colliders. Allnext-to-leading order perturbative contributions from quark-antiquark,gluon-(anti)quark, and gluon-gluon subprocesses are included, as well asall-orders resummation of initial-state gluon radiation valid atnext-to-next-to-leading logarithmic accuracy. The region of phase space isspecified in which the calculation is most reliable. Good agreement isdemonstrated with data from the Fermilab Tevatron, and predictions are made formore detailed tests with CDF and DO data. Predictions are shown fordistributions of diphoton pairs produced at the energy of the Large HadronCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgsboson are contrasted with those produced from QCD processes at the LHC, showingthat enhanced sensitivity to the signal can be obtained with judiciousselection of events.', 'We describe a new algorithm, the $(k,\\\\\\\\ell)$-pebble game with colors, and useit obtain a characterization of the family of $(k,\\\\\\\\ell)$-sparse graphs andalgorithmic solutions to a family of problems concerning tree decompositions ofgraphs. Special instances of sparse graphs appear in rigidity theory and havereceived increased attention in recent years. In particular, our coloredpebbles generalize and strengthen the previous results of Lee and Streinu andgive a new proof of the Tutte-Nash-Williams characterization of arboricity. Wealso present a new decomposition that certifies sparsity based on the$(k,\\\\\\\\ell)$-pebble game with colors. Our work also exposes connections betweenpebble game algorithms and previous sparse graph algorithms by Gabow, Gabow andWestermann and Hendrickson.']\n"
     ]
    }
   ],
   "source": [
    "print(cat[:2])\n",
    "print(title[:2])\n",
    "print(ab[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([title, ab, cat])\n",
    "df = df.transpose()\n",
    "df.columns = ['Title', 'Abstract', 'Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>A fully differential calculation in perturbati...</td>\n",
       "      <td>physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>We describe a new algorithm, the $(k,\\\\ell)$-p...</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The evolution of the Earth-Moon system based o...</td>\n",
       "      <td>The evolution of Earth-Moon system is describe...</td>\n",
       "      <td>physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A determinant of Stirling cycle numbers counts...</td>\n",
       "      <td>We show that a determinant of Stirling cycle n...</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From dyadic $\\\\Lambda_{\\\\alpha}$ to $\\\\Lambda_...</td>\n",
       "      <td>In this paper we show how to compute the $\\\\La...</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Calculation of prompt diphoton production cros...   \n",
       "1           Sparsity-certifying Graph Decompositions   \n",
       "2  The evolution of the Earth-Moon system based o...   \n",
       "3  A determinant of Stirling cycle numbers counts...   \n",
       "4  From dyadic $\\\\Lambda_{\\\\alpha}$ to $\\\\Lambda_...   \n",
       "\n",
       "                                            Abstract Category  \n",
       "0  A fully differential calculation in perturbati...  physics  \n",
       "1  We describe a new algorithm, the $(k,\\\\ell)$-p...     math  \n",
       "2  The evolution of Earth-Moon system is describe...  physics  \n",
       "3  We show that a determinant of Stirling cycle n...     math  \n",
       "4  In this paper we show how to compute the $\\\\La...     math  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while the above preview makes it seem as though the characters JSON used for the math formatting are being rendered, but the cell below shows that this is not the case (i.e., the text is still normal text). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From dyadic $\\\\\\\\Lambda_{\\\\\\\\alpha}$ to $\\\\\\\\Lambda_{\\\\\\\\alpha}$'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Title'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['22 ', ' 33']\n"
     ]
    }
   ],
   "source": [
    "lat = '22 $$ 33'\n",
    "pop = lat.split('$')\n",
    "pop.remove('')\n",
    "print(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby('Category').Abstract.count().plot.bar(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out these are the only 6 categories that actually show up in the portion of the dataset that we chose to work with. Oh well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following makes use of this resource: https://towardsdatascience.com/multi-class-text-classification-with-sklearn-and-nltk-in-python-a-software-engineering-use-case-779d4a28ba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "words = stopwords.words(\"english\")\n",
    "df['Cleaned Title'] = df['Title'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z0-9]\", \" \", x).split() if i not in words]).lower())\n",
    "df['Cleaned Abstract'] = df['Abstract'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z0-9]\", \" \", x).split() if i not in words]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Category</th>\n",
       "      <th>Cleaned Title</th>\n",
       "      <th>Cleaned Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>A fully differential calculation in perturbati...</td>\n",
       "      <td>physics</td>\n",
       "      <td>calcul prompt diphoton product cross section t...</td>\n",
       "      <td>a fulli differenti calcul perturb quantum chro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>We describe a new algorithm, the $(k,\\\\ell)$-p...</td>\n",
       "      <td>math</td>\n",
       "      <td>sparsiti certifi graph decomposit</td>\n",
       "      <td>we describ new algorithm k ell pebbl game colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The evolution of the Earth-Moon system based o...</td>\n",
       "      <td>The evolution of Earth-Moon system is describe...</td>\n",
       "      <td>physics</td>\n",
       "      <td>the evolut earth moon system base dark matter ...</td>\n",
       "      <td>the evolut earth moon system describ dark matt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A determinant of Stirling cycle numbers counts...</td>\n",
       "      <td>We show that a determinant of Stirling cycle n...</td>\n",
       "      <td>math</td>\n",
       "      <td>a determin stirl cycl number count unlabel acy...</td>\n",
       "      <td>we show determin stirl cycl number count unlab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From dyadic $\\\\Lambda_{\\\\alpha}$ to $\\\\Lambda_...</td>\n",
       "      <td>In this paper we show how to compute the $\\\\La...</td>\n",
       "      <td>math</td>\n",
       "      <td>from dyadic lambda alpha lambda alpha</td>\n",
       "      <td>in paper show comput lambda alpha norm alpha g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Calculation of prompt diphoton production cros...   \n",
       "1           Sparsity-certifying Graph Decompositions   \n",
       "2  The evolution of the Earth-Moon system based o...   \n",
       "3  A determinant of Stirling cycle numbers counts...   \n",
       "4  From dyadic $\\\\Lambda_{\\\\alpha}$ to $\\\\Lambda_...   \n",
       "\n",
       "                                            Abstract Category  \\\n",
       "0  A fully differential calculation in perturbati...  physics   \n",
       "1  We describe a new algorithm, the $(k,\\\\ell)$-p...     math   \n",
       "2  The evolution of Earth-Moon system is describe...  physics   \n",
       "3  We show that a determinant of Stirling cycle n...     math   \n",
       "4  In this paper we show how to compute the $\\\\La...     math   \n",
       "\n",
       "                                       Cleaned Title  \\\n",
       "0  calcul prompt diphoton product cross section t...   \n",
       "1                  sparsiti certifi graph decomposit   \n",
       "2  the evolut earth moon system base dark matter ...   \n",
       "3  a determin stirl cycl number count unlabel acy...   \n",
       "4              from dyadic lambda alpha lambda alpha   \n",
       "\n",
       "                                    Cleaned Abstract  \n",
       "0  a fulli differenti calcul perturb quantum chro...  \n",
       "1  we describ new algorithm k ell pebbl game colo...  \n",
       "2  the evolut earth moon system describ dark matt...  \n",
       "3  we show determin stirl cycl number count unlab...  \n",
       "4  in paper show comput lambda alpha norm alpha g...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this paper we show how to compute the $\\\\\\\\Lambda_{\\\\\\\\alpha}$ norm, $\\\\\\\\alpha\\\\\\\\ge0$, using the dyadic grid. This result is a consequence of the description ofthe Hardy spaces $H^p(R^N)$ in terms of dyadic and special atoms.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[4,:]['Abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in paper show comput lambda alpha norm alpha ge0 use dyadic grid thi result consequ descript ofth hardi space h p r n term dyadic special atom'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[4,:]['Cleaned Abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2907)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df= 3, stop_words=\"english\", ngram_range=(1, 2))\n",
    "title_final_features = vectorizer.fit_transform(df['Cleaned Title']).toarray()\n",
    "title_final_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title training and testing sets\n",
    "X_t = title_final_features\n",
    "Y_t = df['Category']\n",
    "X_t_train, X_t_test, y_t_train, y_t_test = train_test_split(X_t, Y_t, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.blopig.com/blog/2017/07/using-random-forests-in-python-with-scikit-learn/\n",
    "# RANDOM FOREST\n",
    "rf_t = RandomForestClassifier(n_estimators=100)\n",
    "rf_t.fit(X_t_train, y_t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackabuse.com/text-classification-with-python-and-scikit-learn/\n",
    "y_t_pred = rf_t.predict(X_t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(accuracy_score(y_t_test, y_t_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an 82.88% accuracy in predicting the category of a paper based on its title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 17747)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_final_features = vectorizer.fit_transform(df['Cleaned Abstract']).toarray()\n",
    "abstract_final_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract training and testing sets\n",
    "X_a = abstract_final_features\n",
    "Y_a = df['Category']\n",
    "X_a_train, X_a_test, y_a_train, y_a_test = train_test_split(X_a, Y_a, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.blopig.com/blog/2017/07/using-random-forests-in-python-with-scikit-learn/\n",
    "# RANDOM FOREST\n",
    "rf_a = RandomForestClassifier(n_estimators=100)\n",
    "rf_a.fit(X_a_train, y_a_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackabuse.com/text-classification-with-python-and-scikit-learn/\n",
    "y_a_pred = rf_a.predict(X_a_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8736\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_a_test, y_a_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an 87.3% accuracy in predicting the category of a paper based on its abstract. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physics 3565\n",
      "math 1174\n",
      "q-bio 64\n",
      "cs 174\n",
      "q-fin 7\n",
      "stat 16\n",
      "0.713\n"
     ]
    }
   ],
   "source": [
    "ratio_sum = ph_sum = 0\n",
    "for i in df['Category'].unique():\n",
    "    print(i, (df['Category'] == i).sum())\n",
    "    if i != 'physics':\n",
    "        ratio_sum += (df['Category'] == i).sum()\n",
    "    else:\n",
    "        ph_sum = (df['Category'] == i).sum()\n",
    "print(ph_sum / (ratio_sum + ph_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio of physics to total paper is less than the accuracy (73% < 83% and < 87%). Therefore, the algorithm did better than just guessing \"physics\" all the time. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
